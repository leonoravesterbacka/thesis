\chapter{Background Estimations}\label{sec:backgrounds}
\noindent
\justify
The SM backgrounds in this search are well known and allows for the use of data-driven background estimation techniques. 
Further, some backgrounds are estimated from simulation with designated control region to validate the normalization. 
The background composition differs depending on if the search has a \PZ boson selection (such as for the colored and electroweak superpartner searches) or a \PZ boson veto (such as for the Edge and direct slepton search). 
This results in, on the one hand, a significant contribution from Drell-Yan, on the other hand, a suppression thereof. 
In the signal region where Drell-Yan makes up a significant fraction, a data-driven technique is used that predicts the \ptmiss spectrum in \PZ+jets events by the \ptmiss spectrum in $\gamma$+jets events. 
In the slepton search, the Drell-Yan is heavily suppressed by stringent cuts on \ptmiss, number of jets and \mttwo, so this very minor fraction is estimated from simulation.  
What is common to all the searches is the contribution from processes containing one or more top quarks or \PW bosons that decay leptonically. 
These processes are referred to in the following as flavor symmetric (FS), due to the flavor symmetry of the \PW boson decay. 
This background is estimated using a data-driven technique. 
Diboson processes are also present in most SRs if one or two of the leptons are out of acceptance or are not well reconstructed. 
Together with the \ttZ process, these processes are referred to as "Z+$\nu$" backgrounds, as they all contain prompt leptons and \ptmiss from a neutrino.   
\newpage
\section{Flavor-symmetric background}\label{sec:fsBG}
\noindent
\justify
Physical processes that feature decays into same flavor and opposite flavor lepton pairs with equal probability is comprised in this background estimation. 
This is, mainly the \ttbar process, but also other processes such as \PWW, or \ttW production.
The idea behind the background prediction technique is visualized in Figure \ref{fig:rsfofMC} where a selection of same flavor and opposite flavor leptons is applied in an Edge-like signal region in simulation, showing that the \ttbar sprectrum has the same shape and magnitude in both selections.    
\begin{figure}[htbp!]
\begin{center}
    \includegraphics[width=0.45\textwidth]{images/rsfof/FSSF.pdf}
    \includegraphics[width=0.45\textwidth]{images/rsfof/FSOF.pdf} 
    \caption{The invariant dilepton mass distribution after requiring a baseline SR definition for the Edge search in addition to an opposite-sign, same-flavor (left) or opposite-sign opposite-flavor (right) lepton pair. The simulated background events are stacked on top of each other.}
\label{fig:rsfofMC}
\end{center}
\end{figure}                                                                               
Other processes such as \PWZ production or \ttZ and \ttH production have some flavor symmetric component and some component stemming from the decay of the \PZ boson.
These processes are treated separately in Section \ref{sec:Znu} and are referred to as "Z+$\nu$" processes. 
The FS background prediction in SF events utilizes the number of OF events as follows:
\begin{align}
\label{eq:masterformula}
    N_{\Pe\Pe} & = R_{\Pe\Pe/OF} \times N_{OF}\notag \\
    N_{\mu\mu} & = R_{\mu\mu/OF} \times N_{OF}\notag\\
    N_{SF} \equiv N_{\Pe\Pe} + N_{\mu\mu} & = R_{SF/OF} \times N_{OF}
\end{align}
As dictated by physics, the ratios $R$ should simply be $R_{\Pe\Pe/OF}=R_{\mu\mu/OF}=0.5$ and $R_{SF/OF}=1$.
But since it is impossible to have a perfect detector in such a large scale experiment, the ratios are slightly off from 0.5 and 1. 
This is due to trigger, reconstruction and identification efficiencies that are not identical for detected electrons and muons. 
So instead of just using the assumptions on the ratios to be 0.5 or 1, the ratios are instead measured to take into account these differences in efficiencies. 
In the following is a derivation on how the number of SF events can be estimated, with the following naming scheme used: 
An epsilon without an upper index includes all efficiencies (trigger, selection and reconstruction), an epsilon with "$R$" as a superscript indicates that reconstruction and selection efficiencies are applied, an epsilon with "$T$" as a superscript indicates that trigger efficiencies are applied while the superscript "hard" stands for the quantity on particle level.
An assumption is made on the reconstruction and selection efficiencies for the two leptons in the event to be uncorrelated, i.e. $\epsilon_{\ell\ell}=\epsilon_{\ell} \cdot \epsilon_{\ell}$. 
The ratio of efficiencies for muons to electrons is basically saying how well muons are measured with respect to electrons given certain trigger and reconstruction selection. 
The quantity can be expressed in the following way:
\begin{align}
\label{eq:rMue}
r_{\mu/e} & = \frac{\epsilon_{\mu}}{\epsilon_{e}} \approx \sqrt{ \frac{\epsilon^{R}_{\mu\mu}\epsilon^{T}_{\mu\mu}}{\epsilon^{R}_{ee}\epsilon^{T}_{ee}}} = \sqrt{ \frac{N_{\mu\mu}}{N_{ee}}} \notag \\
r_{\mu/e} & \approx r^{R}_{\mu/e}\sqrt{ \frac{\epsilon^{T}_{\mu\mu}}{\epsilon^{T}_{ee}}}
\end{align}
From this, the number of ee and $\mu\mu$ events can be estimated in the following way:
\begin{align}
\label{eq:eemumuFormula}
N_{ee} & = \epsilon^{T}_{ee} N^{R}_{ee} = \epsilon^{T}_{ee} \left(\epsilon^{R}_{e}\right)^{2} N^{hard}_{ee} = \frac{1}{2} \epsilon^{T}_{ee} \left(\epsilon^{R}_{e}\right)^{2} N^{hard}_{OF} 
										= \frac{1}{2} \epsilon^{T}_{ee} \frac{\epsilon^{R}_{e}}{\epsilon^{R}_{\mu}} N^{R}_{OF} \notag \\
       & =\frac{1}{2} \frac{1}{r^{R}_{\mu/e}} \frac{\epsilon^{T}_{ee}}{\epsilon^{T}_{e\mu}}N_{OF} 
										= \frac{1}{2} \frac{1}{r_{\mu/e}} \frac{\sqrt{\epsilon^{T}_{ee}\epsilon^{T}_{\mu\mu}}}{\epsilon^{T}_{e\mu}} N_{OF}  \notag \\
N_{\mu\mu} & = \epsilon^{T}_{\mu\mu} N^{R}_{\mu\mu} = \epsilon^{T}_{\mu\mu} (\epsilon^{R})^{2}_{\mu} N^{hard}_{\mu\mu} = \frac{1}{2} \epsilon^{T}_{\mu\mu} (\epsilon^{R})^{2}_{\mu} N^{hard}_{OF}
										= \frac{1}{2} \epsilon^{T}_{\mu\mu} \frac{\epsilon^{R}_{\mu}}{\epsilon^{R}_{e}} N^{R}_{OF}  \notag \\
	  & =\frac{1}{2} r^{R}_{\mu/e} \frac{\epsilon^{T}_{\mu\mu}}{\epsilon^{T}_{e\mu}}N_{OF} = \frac{1}{2} r_{\mu/e} \frac{\sqrt{\epsilon^{T}_{ee}\epsilon^{T}_{\mu\mu}}}{\epsilon^{T}_{e\mu}} N_{OF}
\end{align}
As the final destination for this derivation is the prediction of SF yields, the above equalities can be combined to give an estimate of the $N_{SF}$:
\begin{align}
\label{eq:masterformulaExp}
    N_{SF} & = \frac{1}{2} \left( r_{\mu/e} + \frac{1}{r_{\mu/e}} \right) \frac{\sqrt{\epsilon^{T}_{ee}\epsilon^{T}_{\mu\mu}}}{\epsilon^{T}_{e\mu}} N_{OF}  \notag \\
           & = \frac{1}{2} \left( r_{\mu/e} + \frac{1}{r_{\mu/e}} \right) R_{T} N_{OF} = R_{SF/OF} N_{OF}
\end{align}                                                                                                                                                                  
This parametrization underlines the advantage of using the combined SF sample compared to the separate $\ElEl$ and $\MuMu$ samples.
While $R_{\ell\ell/OF}$ is directly affected by the differences in reconstruction and trigger efficiencies by the factors \rmue or \rmueinv, these differences partially cancel out in \Rsfof. 
In order to get to a final value for \Rsfof, two approaches have been taken. 
The first is a direct measurement of the ratio \Rsfof in data in a control region enriched in \ttbar, while the second consists of the separated estimation of the \rmue and $R_T$ factors.
This section contains a description of the direct measurement method, followed by a description of the factorization method. 
Lastly, the different treatment of the FS background in the edge, On-Z and slepton searches is presented.  
\subsection*{Direct measurement method}\label{sec:rsfofDirect}
\noindent
\justify
The direct measurement of the \Rsfof is the ratio of SF to OF events in a \ttbar enriched control region. 
This region is defined orthogonal to the signal regions in terms of jets and \ptmiss. 
It lies just outside them in order to not be affected by a large extrapolation. 
The exact selections for this \Rsfof-measurement control region are:
\begin{itemize}
    \item the same lepton selection
    \item exactly two jets
    \item \ptmiss between 100 and 150\GeV
    \item $70\geq\mll\geq110\GeV$ excluded
\end{itemize}                                 
Even though all signal regions are defined with a \mttwo cut, the choice is made to not define the \ttbar CR with a \mttwo requirement. 
The reason for this is the significant reduction of the \ttbar background and thus the available statistics that the \mttwo requirement would lead to.
A large mass window around the \PZ boson mass is excluded to avoid the contamination with DY backgrounds. 
The measurement consist of counting the number of ee, $\mu\mu$ and SF events in this control region, and taking the ratio of this number to the number of OF events in the same region, to construct the \Reeof, \Rmmof and \Rsfof separately. 
The results are shown in Tab.~\ref{tab:rSFOF} and the data and the simulation agree within 2\% for the combination of both flavors. 
If the flavors are treated seperately, the data MC agreement is between 1 and 3\%. 
As a closure test, the ratio of \Rsfof in the control and signal region (transfer factor) on simulation is studied. 
It is found to be compatible with unity within 2\%  for the combination of both flavors and for each flavor seperately.
\begin{table}[ht!]
\def\arraystretch{1.2}
\setlength{\belowcaptionskip}{6pt} 
\small                            
\centering                           
\caption{Observed event yields in the control region and the resulting values for $R_{SF/OF}$, $R_{ee/OF}$, and $R_{\mu\mu/OF}$ for both data and MC. 
The transfer factor is defined as the ratio of $R_{SF/OF}$ in the signal region devided by $R_{SF/OF}$ in the control region.}
\label{tab:rSFOF}
\begin{tabular}{ l c c c}
        \hline \hline
        & $N_{SF}$ & $N_{OF}$ & $ R_{SF/OF} \pm \sigma_{stat}$  \\    
        \hline
         Data & 13438 & 12138 & 1.107$\pm$0.014\\
         MC   & 13290 & 12189 & 1.090$\pm$0.005\\ 
        \hline
         & $N_{ee}$ & $N_{OF}$ & $ R_{ee/OF} \pm \sigma_{stat}$ \\    
        \hline
         Data & 4976 & 12138 & 0.410$\pm$0.007 \\
         MC   & 4852 & 12189 & 0.398$\pm$0.003 \\
        \hline
         & $N_{\mu\mu}$ & $N_{OF}$ & $ R_{\mu\mu/OF} \pm \sigma_{stat}$\\    
        \hline
         Data & 8462 & 12138 & 0.697$\pm$0.010 \\
         MC   & 8438 & 12189 & 0.692$\pm$0.004 \\ \hline\hline
\end{tabular}
\end{table}                                                                                                                                                                    
To evaluate possible dependencies when extrapolating from control to signal region and determine a systematic uncertainty, the ratio \Rsfof is studied by relaxing each of the control region variables and check the evolution of the \Rsfof as a function if the same variable, in data and simulation.  
The data shows some fluctuations due to the limited statistics in the control region, but no clear trends are observed.
These studies are used to assign a systematic uncertainty as the variation of the \Rsfof that would be sufficient to cover the differences between the data and the simulation. 
It is found that a variation 4\% is enough cover any potential fluctuations and is assigned as a systematic uncertainties. 
\subsection*{Factorization method}\label{sec:factorizationMethod}
\noindent
\justify
The second method to predict the number of SF events in the SR is called the Factorization method and explicitly takes into account the trigger and recontruction efficiencies of the leptons.   
In order to calculate \Rsfof according to Eq.~\ref{eq:masterformulaExp}, \rmue and \RT are measured in data.
\subsubsection*{Measurement of \rmue}
\noindent
\justify
The measurement of \rmue is performed in a high statistics DY enriched control region summarized below:
\begin{itemize}
    \item the same lepton selection
    \item more than or exactly two jets
    \item \ptmiss below 50\GeV
    \item $60\geq\mll\geq120\GeV$
\end{itemize}                                 
A small dependency on \rmue is found as a function of the second lepton \pt is observed, especially at low \pt where the muons are reconstructed at a higher efficiency than electrons.  
In order to correct for this trend, a paramterization of this dependency is performed. The following parameterization as a function of the \pt of the second lepton was chosen:
\begin{equation}
    r_{\mu/e}  = a +  \frac{b}{\pt}
\label{eq:rMuEFormular}
\end{equation}
$a$ and $b$ are constants that are determined in a fit to data.
The fit for this parameterization is shown in Figure \ref{fig:rMuEDependency}.
\begin{figure}[htbp!]
\begin{center}
    \includegraphics[width=0.45\textwidth]{images/rsfof/rMuE_ZPeakControl_Run2016_36fb_TrailingPt_None.pdf}
    \includegraphics[width=0.45\textwidth]{images/rsfof/rMuE_ZPeakControl_Run2016_36fb_TrailingPt_corrected.pdf}
    \caption{The \rmue dependency on the \pt of the second lepton for data and MC. The plots show the values for \rmue before (left) and after (right) the parameterization on the second lepton \pt is propagated to the dielectron events. The central value in the left plot indicates the \rmue value that would be obtained without the parameterization. The fit values of the parameterization are shown in the left plot.}
\label{fig:rMuEDependency}
\end{center}
\end{figure}                                                                                                                
The determined parameters are stated in Tab.~\ref{tab:rMuEFitParameters}.
\begin{table}[ht!]
\def\arraystretch{1.2}
\setlength{\belowcaptionskip}{6pt} 
\small                            
\centering                           
\caption{Result of the fit of \rmue as a function of the \pt of the trailing lepton in the DY control region. The same quantaties derived from simulation are shown for comparison. Only statistical uncertainties are given.}
\label{tab:rMuEFitParameters}
\begin{tabular}{ l c c }
        \hline \hline
    		& $a$ & $b$ \\\hline
        Data     &  1.14$\pm$0.01  &  5.20$\pm$0.16    \\
        MC       &  1.16$\pm$0.01  &  5.15$\pm$0.36    \\\hline\hline
\end{tabular}
\end{table}                                                                                                                                                                   
Since the effect is mainly at very low lepton \pt and less than 5\% of the events fall into this category, a flat systematic uncertainty of 10\% is chosen to cover this remaining trend 
instead of doing a mutli-variable fit. 
An uncertainty band indicates these 10\% in Figure \ref{fig:rMuEDependency} (right) that shows the corrected $r_{\mu/e}^{corr.}$ for the second lepton \pt. 
Further dependencies of $r_{\mu/e}^{corr.}$ on important observables are studied and no significant trends are observed. 
The chosen 10\% systematic uncertainty is sufficient to cover any remaining trends in these observables.
In addition to the studies on the dependence of $r_{\mu/e}^{corr.}$ on different variables, the dependency on the 0.5($r_{\mu/e}^{corr.}+1/r_{\mu/e}^{corr.}$), which is the factor that actually go in to the prediction of the $N_{SF}$ as seen in Equation \ref{eq:masterformulaExp}, on some SR variables is also performed. 
This is especially important as the control region where the \rmue is measured is far from the signal regions. 
In Figure \ref{fig:RDependency} the results of some of these studies can be observed where the results on data are shown in black and simulation in green. 
The central value observed on data is indicated by a dashed line. 
To determine the systematic uncertainty the fit parameters $a$ and $b$ are varied by its statistical uncertainty and the full prediction is shifted up and down by the 10\% systematic uncertainty from the studies above.
The relative change of the mean value is used as the systematic uncertainty of the method. 
The quantity 0.5($r_{\mu/e}^{corr.}+1/r_{\mu/e}^{corr.}$) is especially stable with respect to \ptmiss and \mttwo, as can be seen in Figure \ref{fig:RDependency}, validating the extrapolation from the DY control region to the signal region.   
\begin{figure}[htbp!]
\begin{center}
    \includegraphics[width=0.45\textwidth]{images/rsfof/rSFOFFromRMuE_ZPeakControl_Run2016_36fb_MET_corrected.pdf}
    \includegraphics[width=0.45\textwidth]{images/rsfof/rSFOFFromRMuE_ZPeakControl_Run2016_36fb_MT2_corrected.pdf}
    \caption{The 0.5($r_{\mu/e}^{corr.}+1/r_{\mu/e}^{corr.}$) dependency on \ptmiss (left) and \mttwo (right) for data and MC after the parameterization on the second lepton \pt is propagated to the dielectron events. The uncertainty introduced by shifting the fit parameters by its statistical uncertainty and the full prediction by 10\% is indicated by the orange band.}
\label{fig:RDependency}
\end{center}
\end{figure}                                                                                                                                                                                
\subsubsection*{Measurement of \RT}\label{sec:rt}
\noindent
\justify
The second ingredient in the Factorization method for predicting the $N_{SF}$ in the signal region is the \RT, which is a measure of the trigger efficiencies. 
The \RT is defined through the trigger efficiencies, $\epsilon_{ll}^{T}$,  according to:
\begin{equation}
\label{eq:masterformulaExp}
    \RT = \frac{\sqrt{\epsilon^{T}_{ee}\epsilon^{T}_{\mu\mu}}}{\epsilon^{T}_{e\mu}}
\end{equation}                                               
The trigger efficiencies are measured using a data sample collected with Particle Flow \HT triggers, in which dilepton events are selected. 
This way, the efficiencies of the lepton triggers can be studied by comparing how many of the dilepton events in the \HT triggered data sample was also picked up by the dilepton triggers. 
The PF \HT triggers used have thresholds between 125\GeV and 900\GeV, and the dilepton triggers studied are listed in Table \ref{tab:triggers} in Section \ref{sec:trigger}. 
The dilepton trigger efficiency is calculated as the fraction of events in the lepton unbiased sample that also passes the dilepton triggers for the given flavor combination: 
\begin{equation}
\epsilon_{ll}^{T} =\frac{ll\text{ selection }\cap \HT \text{ trigger } \cap ll\text{ trigger}  }{ ll\text{ selection }\cap \HT \text{ trigger }} .
\label{eq:rt}
\end{equation} 
No particular requirement is applied to the data sample, except all events in the signal regions or in the \ttbar control region used for the direct measurement of \Rsfof are exluded. 
In terms of number of jets and \ptmiss, this translated to $\nj\geq2$ and $\ptmiss\geq100\GeV$, and in order to be fully efficient in terms of the \HT triggers, a requirement on the offline $\HT\geq200\GeV$ is imposed.  
The result of the trigger efficiencies measurement in data and simulation is shown in Table \ref{tab:TriggerEffValues}. 
The number of events is much larger in simulation as no \HT cross triggers are required.
The efficiencies in data are about 96\% for dielectron triggers, 95\% for dimuon triggers and 91\% for electron-muon triggers. 
This leads to a value for \RT of 1.052, from the equality in Equation \ref{eq:rt}. 
The efficiencies for dimuon and electron-muon on MC are 2-3\% higher, but $\RT=1.045$ is close to the value on data.
A systematic uncertainty of 3\% is chosen and assinged to each trigger efficiency, which corresponds to the maximal deviation between the efficiencies in data and simulation.
This results in a total uncertainty of about 4\% on \RT after error propagation of the individual uncertainties on the efficiencies.
Similarly to the direct measurement of \Rsfof and \rmue, the dependence on some signal region variables is studied, and is shown in Fig.~\ref{fig:EffDependency}. 
No significant dependency of \RT on any event property is observed and the chosen systematic uncertainty is sufficient to cover any fluctuation in data and MC. 
\begin{table}[ht!]
\def\arraystretch{1.2}
\setlength{\belowcaptionskip}{6pt} 
\small                            
\centering                           
\caption{Trigger efficiency values for data and MC with OS, $p_T>25(20)\,\GeV$ and $H_T>200\,\GeV$.} 
\label{tab:TriggerEffValues}
\begin{tabular}{l c c c |c c c}  
\hline \hline
&\multicolumn{3}{c|}{Data} &\multicolumn{3}{c}{MC} \\\hline
& nominator & denominator & $\epsilon_{trigger} \pm \sigma_{stat}$ & nominator & denominator & $\epsilon_{trigger} \pm \sigma_{stat}$ \\    \hline
ee & 12070 & 12584 & 0.959$\pm$0.002 & 111787 & 116654 & 0.958$\pm$0.001 \\
$\mu\mu$ & 8741 & 9230 & 0.947$\pm$0.002 & 190067 & 194687 & 0.976$\pm$0.001 \\
e$\mu$ & 2437 & 2690 & 0.906$\pm$0.006 & 43069 & 46520 & 0.926$\pm$0.000 \\
\hline
$R_{T}$ & \multicolumn{3}{c|}{1.052$\pm$0.043}  & \multicolumn{3}{c}{1.045$\pm$0.041}  \\\hline\hline
\end{tabular}
\end{table}                                                                                                                                           
\begin{figure}[htbp!]
\begin{center}
    \includegraphics[width=0.45\textwidth]{images/rsfof/Triggereff_SFvsOF_Syst_PFHT_HighHTExclusive_Run2016_36fb_MET_None_MC.pdf}
    \includegraphics[width=0.45\textwidth]{images/rsfof/Triggereff_SFvsOF_Syst_PFHT_HighHTExclusive_Run2016_36fb_MT2_None_MC.pdf}
    \caption{Dependency of the \RT ratio on the \ptmiss (left) and \mttwo (right), for data and MC. The systematic uncertainty of about 4\% on \RT is indicated by the orange band.}
\label{fig:EffDependency}
\end{center}
\end{figure}                                                                                                                                                                              
The results from the direct and factorization methods for the FS background prediction have comparable uncertainties and central values, and can thus be combined using the weighted average. 
For the factorization method, no constant result for the \Rsfof can be given, due to the parameterization of \rmue that has to be applied on an event-to-event basis.
Instead, the factorization method is applied in each SR where the obtained prediction is divided by the number of OF events to get an \Rsfof factor for the factorization method in this region. 
This factor is combined with \Rsfof from the direct measurement method by using the weighted average.
The \Rsfof values obtained by the direct measurement are the same for all signal regions as they are derived in one control region, and are given in Table \ref{tab:rSFOF}. 
\section{Z+$\nu$ background}\label{sec:Znu}
\noindent
\justify
The group of SM backgrounds called Z+$\nu$ processes have in common that they all produce a dilepton pair compatible with the \PZ boson and one or more neutrinos from a \PZ or \PW decay. 
These processes are not strictly flavor symmetric, as more SF lepton pairs are produced than OF lepton pairs, and they are not DY processes where the \ptmiss is stemming from instrumental effects. 
There are many SM processes like this, and the highest cross section ones that contribute significantly to the various signal regions are \PWZ, \PZZ and \ttZ. 
The \PWZ produce three charged leptons at particle level and one neutrino and is through the third lepton veto in the signal region heavily suppressed. 
However, if the third lepton is for some reason not reconstructed, this process enter the signal regions.  
The \PZZ process produce two charged leptons and two neutrinos, and thus enter the signal regions through the large \ptmiss from the neutrinos. 
This process contribute significantly to the slepton signal region, as to first order no jets are produced. 
The \ttZ process produce two leptons compatible with a \PZ boson, and jets and \ptmiss from the decay of the top quarks. 
Although this is not a high cross section process, it still enters the on-Z signal regions. 
All these processes are estimated from simulation, but as the signal region phase space is low in statistics and not always well modelled, it is important to validate the simulation in dedicated orthogonal control regions. 
The control region validation for the three different processes is presented in the following, and with slightly different treatment depending on the signal region.  
\subsection*{\PWZ$\rightarrow3l\nu$ background}
\noindent
\justify
Since the signal models considered should only contain a final state with two leptons, a veto is applied on events containing more than two leptons, more precisely in the form of additional isotracks
 detailed in Section \ref{sec:isotracks}. 
As these additional isotracks are required to have a \pt $>$ 5 GeV and be within $|\eta|$ $<$ 2.4, there is still a possibility for these leptons to not be reconstructed if they fall out of acceptance, and thus the event is not vetoed. 
This kind of background is dominated by the \PWZ$\rightarrow3l\nu$ process.
The reason why the events fail the third lepton veto is due to the low \pt leptons that fail the \pt requirement of 5 GeV. 
What is also worth noting is that the larger fraction of these events have a third lepton originating from a \PZ boson. 
In the cases where the lost lepton is from the \PZ boson, the resulting lepton pair contribution is FS, meaning SF lepton pairs are produced at the same rate as OF lepton pairs. 
This contribution is covered by the data-driven FS background prediction technique presented in Section\ref{sec:fsBG}.
On the other hand, if the lost lepton is originating from the decay of the \PW boson, the leptons from this background process is dominantly same flavor. 
In order to treat these backgrounds in a correct way and avoid double counting contributions, the leptons from the \PWZ process is estimated from simulation only if both leptons are originating from a \PZ boson decay. 
To validate that the simulation is properly modelling the \ptmiss tails where the signal regions are defined, an orthogonal control region is constructed by inverting the third lepton veto. 
By requiring 3 well identified leptons, the region is orthogonal to the signal region. 
The rest of the requirements are summarized below, where the idea is to obtain a region pure in \PWZ contribution while keeping the definition close to the signal region definition. 
As the signal regions for the slepton search differ from the rest of the searches in terms of the jet requirement, the validation of the \PWZ simulation is done in two separate control regions. 
One control region is closer to the on-Z searches and require more than 2 jets and the other one is closer to the slepton signal region and require no jets. 
From these different control regions, transfer factors are derived for the different searches, that are later applied to the simulation in the respective signal regions. 
The control regions and the final transfer factors are introduced for the various analysis strategies presented in Chapters \ref{sec:strong}, \ref{sec:ewk} and \ref{sec:slepton}. 
\subsection*{\PZZ$\rightarrow 2l2\nu$ background}\label{ZZ}
\noindent
\justify
The second largest background in this search is stemming from the production of two Z bosons decaying to two leptons and two neutrinos. 
Although this process is suppressed by the jet requirement in the on-Z signal regions, it can still contribute as it is a process containing a production of a leptonically decaying \PZ boson. 
In the slepton search, on the other hand, the contribution is enhanced as to first order no jets are produced. 
But since the slepton signal region is designed with a veto on leptons compatible with a \PZ boson, this process can only enter the signal region if the \PZ boson is off-shell and produce leptons with an invariant mass far away from the on-shell \PZ boson mass. 
The simulation is validated for both scenarios separately, and transfer factors are derived for the on-Z and slepton searches separately. 
Similarly as to the \PWZ$\rightarrow3l\nu$ background, the control regions and the final transfer factors are introduced for the various analysis strategies presented in Chapters \ref{sec:strong}, \ref{sec:ewk} and \ref{sec:slepton}. 
\section{Drell-Yan background}\label{sec:mettemplates}
\noindent\justify
The Drell-Yan process, i.e. $\PZ+$jets process, enter all signal regions in the searches presented in this thesis. 
The \ptmiss in the $\PZ+$jets process is solely due to the hadronic recoil and more precisely due to mismeasured jets. 
A more detailed treatment of the \ptmiss in these events is presented in the chapter on \ptmiss performance in Chapter~\ref{sec:met}. 
What can be seen there is that the shape of the \ptmiss spectrum in $\PZ+$jets is the same as in $\gamma+$jets events, with a difference in the normalization due to the higher cross section associated with the $\gamma+$jets process. 
This similarity in the shape of the \ptmiss spectrum is exploited in this thesis, by estimating the $\PZ+$jets in the signal region from a data sample of $\gamma+$jets in the signal region. 
A single photon data sample is collected using single photon triggers with \pt thresholds of 22-165\GeV. 
The data collected with the prescaled triggers is corrected by the associated prescale values for each data taking period and run. 
As there are differences between the mass of the two bosons, the $\gamma$ \pt spectrum is reweighted to match the $\PZ$ spectrum in each signal region to account for this difference. 
An orthogonal control region with \ptmiss 50-100\GeV is used to normalize the $\gamma+$jets sample to match the $\PZ+$jets sample.
Although suppressed by the lower cross sections and a lepton veto, electroweak processes with real \ptmiss such as $\PW\gamma$ can contribute significantly to the \ptmiss tails in the single $\gamma$ sample.
The contributions from electroweak processes are subtracted from the photon \ptmiss spectrum using simulation. 
The modelling of the simulated electroweak processes is validated in an orthogonal control region containing one muon and one photon. 
There is good agreement observed in this control region and a conservative 30\% systematic uncertainty is assigned to the electroweak subtraction procedure.   
As the \mttwo variable is used to define all signal regions, the \mttwo has to be constructed in the $\gamma+$jets data sample. 
But since two visible objects are needed when calculating the \mttwo, a special treatment is needed since there is only one photon in the events. 
The \mttwol can be emulated in the $\gamma+$jets sample by a simulated decay of the photon to two leptons, and where the \mttwol is calculated with the two decayed leptons as the visible objects.
This decay is done by assuming the mother particle has the mass of a \PZ boson and the \pt of the photon reconstructed from data. 
The angular distribution of the leptons is accounted for by assuming a scenario where the direction of the spin of the mother particle is sampled from a distribution that is uniformly distributed in $1+\cos^{2}(\theta)$, where $\theta$ is the polar angle in the reference frame in which the mother particle is at rest. 
After the photon is decayed, the same \pt and $\eta$ requirements that are applied to the $\PZ+$jets events are applied to the decay products from the photon. 
\mttwol is constructed using these leptons, and the same cut is applied as in each signal region. 
Finally, the \pt distribution is reweighted as described previously.
The final systematic uncertainty assigned to this method is stemming from four sources. 
These sources are the statistical uncertainty of the $\gamma+$jets data sample, a closure method performed in simulation, the normalization performed in the low \ptmiss bin and the electroweak subtraction procedure. 
The closure test in simulation is evaluated separately in each of the signal regions. 
The systematic uncertainty is taken as the larger of the MC statistical uncertainty or non-closure and varies between 10–80\% for the various signal regions.
The statistical uncertainty from the normalization of the template prediction in data in each signal region (using \ptmiss between $50–100\GeV$) as a systematic uncertainty on the prediction. 
This uncertainty ranges from 7–30\% depending on the signal region.
The uncertainty on the electroweak subtraction procedure is chosen to be 30\% as described previously in this section. 
The different treatment of the Drell-Yan background needed for each analysis strategy will be described in Chapters \ref{sec:strong}, \ref{sec:ewk} and \ref{sec:slepton}.   
\section{Rare processes}
\noindent\justify
A final category of Standard Model backgrounds are rare processes, such as  \ttW, \ttH, \tWZ\ and \tZq\ as introduced in Section \ref{search}. 
These processes are neither flavor symmetric nor have all their \ptmiss from instrumental effects. 
Instead they can all result in final states with more two or more leptons, jets and neutrinos, and thus fall in to the various signal regions that require two or more jets. 
Triboson processes, such as \PWWZ, \PWZZ and \PZZZ contribute in the signal regions of the direct slepton search. 
What is common to all these processes is that they have very low cross sections. 
The contribution is taken from simulation and a conservative systematic uncertainty of 50\% is assigned.
The simulated samples and the cross sections of these processes are summarized in Appendix A.  
\section{Fakes}
The attentive reader could now point out that a class of backgrounds is missing, namely that due to so called fakes. 
Due to inefficiencies in reconstruction procedures, or due to faulty detector signals, lepton candidates can be reconstructed that in fact does not correspond to a genuine lepton. 
Additionally, other real particles, such as light-flavor quarks or gluon jets may fake the presence of a light lepton. 
In order for events with one fake lepton to enter the signal region, they have to be reconstructed along with a real lepton \footnote{The probability for two fake leptons in one event is just too small to be considered a sizeable background.}
The standard model background of $\PW+$jets, with the \PW decaying leptonically and one of the jets faking a lepton could potentially lead to a signal like event. 
However, as this process involves the flavor democratic leptonic decay of the \PW boson, this contribution will in the end be flavor symmetric, and thus taken into account by the flavor symmetric background prediction method.  
